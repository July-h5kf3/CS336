# ==================== 数据预处理配置 ====================
preprocess:
  input: /home/acd66/project/CS336/assignment1-basics/tests/fixtures/tinystories_sample_5M.txt
  output: /home/acd66/project/CS336/assignment1-basics/tests/fixtures/tinystories_sample_5M.npy
  vocab: /home/acd66/project/CS336/assignment1-basics/tests/outputs/TinyStoriesV2-GPT4-train_vocab.pkl
  merges: /home/acd66/project/CS336/assignment1-basics/tests/outputs/TinyStoriesV2-GPT4-train_merges.pkl
  special_tokens: "<|endoftext|>"

# ==================== 模型配置 ====================
model:
  d_model: 512
  vocab_size: 10000
  context_length: 256
  d_ff: 1344
  RoPE_theta: 10000
  num_layers: 4
  num_heads: 16

# ==================== 训练配置 ====================
training:
  device: cpu  # 或 cuda
  batch_size: 32
  total_steps: 40000
  max_lr: 1e-3
  min_lr: 1e-5
  warmup_steps: 500
  max_grad_norm: 1.0
  weight_decay: 1e-2
  log_interval: 100
  save_interval: 1000
  eval_interval: 500  # 多少步评估一次验证集
  eval_steps: 10      # 验证时采样多少个 batch
  checkpoint_dir: /home/acd66/project/CS336/assignment1-basics/tests/outputs/checkpoints

# ==================== 数据配置 ====================
data:
  train_path: /home/acd66/project/CS336/assignment1-basics/tests/fixtures/tinystories_sample_5M.npy
  val_path: /home/acd66/project/CS336/assignment1-basics/tests/fixtures/tinystories_val.npy  # 验证集路径

# ==================== WandB 配置 ====================
wandb:
  enabled: true
  project: cs336-transformer
  run_name: tinystories-4layer
  log_interval: 100  # 多少步记录一次到 wandb

# ==================== 推理配置 ====================
inference:
  checkpoint: null          # Checkpoint 路径, null=使用 checkpoint_dir/ckpt_final.pt
  max_new_tokens: 200       # 最大生成 token 数
  temperature: 0.8          # 采样温度, 0=greedy
  top_p: 0.95               # Top-p (nucleus) 采样, 1.0=禁用
  eos_token: "<|endoftext|>"  # EOS token, 遇到则停止生成, null=不停止